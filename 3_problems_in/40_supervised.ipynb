{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "Supervised learning is similar to how we learn in school. \n",
    "\n",
    "First, there is a learning or **training phase** where we **learn from lots of examples**. Examples are essentially a set of questions and their answers.\n",
    "\n",
    "The training phase is then followed by a **testing phase** where we apply our learning to a relatively **small set of previously unseen questions**.\n",
    "\n",
    "Finally, there is an **evaluation** on how well we applied our knowledge to the test questions by **comparing our answers to the correct answers**.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "Most machine learning problems involve predicting a single random variable $\\mathcal{y}$ from one or more random variables $\\mathcal{X}$. \n",
    "\n",
    "The underlying assumption, when we set out to accomplish this, is that the value of $\\mathcal{y}$ is dependent on the value of $\\mathcal{X}$ and the relationship between the two is governed by some unknown function $f$ i.e. \n",
    "\n",
    "$$ \\mathcal{y = f(X)} $$\n",
    "\n",
    "$\\mathcal{X}$ is here simply some data that we have as a pandas Dataframe `pd.DataFrame` whereas $\\mathcal{y}$ here is the target variable, one value for each observation, that we want to predict, as a pandas Series `pd.Series`.\n",
    "\n",
    "<img width=\"80%\" align=\"center\" src=\"../assets/supervised2.png\">\n",
    "\n",
    "<br/>\n",
    "\n",
    "The figure above just depicts the core assumption underlying most machine learning problems. \n",
    "\n",
    "**Assumptions**, loosely speaking, are what we formally call **models**. \n",
    "\n",
    "Therefore, the basic mathematical model underlying most machine learning problems is that the target variable $\\mathcal{y}$ is a function of the input variables $\\mathcal{X}$ i.e. $\\mathcal{y = f(X)}$.\n",
    "\n",
    "If this assumption does NOT hold, then there is nothing to learn and we cannot predict $\\mathcal{y}$ from $\\mathcal{X}$. In other words, $\\mathcal{y}$ is independent of $\\mathcal{X}$. For example, if we try to predict the outcome of a coin toss using the time of day, we will fail miserably because the two are independent of each other.\n",
    "\n",
    "The **core problem**, distinct from any models or assumptions, here is that <u>the function $\\mathcal{f}$ is unknown to us and we need to <i>\"learn\"</i> it from the data</u>. \n",
    "\n",
    "Such problems fall under the broad category of **Supervised Learning**. \n",
    "\n",
    "There are two primary types of supervised learning problems:\n",
    "\n",
    "1. **Classification** - when the target variable $\\mathcal{y}$ is categorical\n",
    "2. **Regression** - when the target variable $\\mathcal{y}$ is continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "**Example Dataset**\n",
    "\n",
    "The code below loads the `iris` dataset from the `sklearn` library. This dataset is a classic example of a classification problem.\n",
    "\n",
    "<center><img width=\"60%\" src=\"https://editor.analyticsvidhya.com/uploads/51518iris%20img1.png\"></center>\n",
    "\n",
    "`X` is a `pandas DataFrame` with 4 columns and 150 rows. Each row represents a flower and each column represents a feature of the flower. The features are:\n",
    "\n",
    "1. sepal length in cm\n",
    "2. sepal width in cm\n",
    "3. petal length in cm\n",
    "4. petal width in cm\n",
    "\n",
    "`y` is a `pandas Series` with 150 rows. Each row represents the species of the flower. The species are:\n",
    "\n",
    "1. Iris Setosa\n",
    "2. Iris Versicolour\n",
    "3. Iris Virginica\n",
    "\n",
    "The goal is to predict the species of a flower given its features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= X - Features ==================\n",
      "\n",
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "73                 6.1               2.8                4.7               1.2\n",
      "18                 5.7               3.8                1.7               0.3\n",
      "118                7.7               2.6                6.9               2.3\n",
      "78                 6.0               2.9                4.5               1.5\n",
      "76                 6.8               2.8                4.8               1.4\n",
      "\n",
      "============== y (Classification) ==============\n",
      "\n",
      "73     1\n",
      "18     0\n",
      "118    2\n",
      "78     1\n",
      "76     1\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris(as_frame=True)\n",
    "X    = data['data']\n",
    "y    = data['target']\n",
    "\n",
    "print(\"\\n================= X - Features ==================\\n\")\n",
    "print(X.sample(5, random_state=42))\n",
    "print(\"\\n============== y (Classification) ==============\\n\")\n",
    "print(y.sample(5, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train-Test Split\n",
    "\n",
    "The first step in supervised learning is to split the data into two sets: a **training set** and a **test set**.\n",
    "\n",
    "The training set is used to _train_ or _learn_ the parameters of the model. The test set is used to evaluate the performance of the learning. \n",
    "\n",
    "The convention is to use majority of the data for training and the rest for testing. The ratio of training to test data is typically 80:20 or 70:30.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<img src=\"../assets/train_test.png\">\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "It is extremely important to ensure the following: \n",
    "\n",
    "1. The training set and test set are **mutually exclusive** i.e. no observation in the training set should be in the test set and vice versa.\n",
    "\n",
    "2. The train and test sets are **representative** of the overall data. For example, if the data is sorted by date, then the train set should have observations from all dates and not just the most recent dates. \n",
    "\n",
    "To ensure this, the train set must be randomly drawn from the data. \n",
    "\n",
    "This can be implemented by randomly shuffling the data before splitting it into train and test sets or using the built-in `.sample` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example\n",
    "\n",
    "The code below uses the **`train_test_split`** function from the `sklearn` library to split the data into train and test sets.\n",
    "\n",
    "The `test_size` parameter is set to `0.2` which means that 20% of the data will be used for testing and the remaining 80% will be used for training.\n",
    "\n",
    "The `random_state` parameter is set to `42` which means that the random number generator will be initialized to a known state. This ensures that the results are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      " X_train.shape = (112, 4) , y_train.shape = (112,)\n",
      "Test set: \n",
      " X_test.shape = (38, 4) , y_test.shape = (38,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Train set:\\n X_train.shape =\", X_train.shape, \", y_train.shape =\", y_train.shape)\n",
    "print(\"Test set: \\n X_test.shape =\",  X_test.shape,  \", y_test.shape =\",  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training Phase\n",
    "\n",
    "In supervised learning problems, we have a set of observations, each observation consisting of a set of input variables $\\mathcal{X}$ and a target variable $\\mathcal{y}$, and we want to learn a function $\\mathcal{f}$ that maps the input $\\mathcal{X}$ to the output $\\mathcal{y}$.\n",
    "\n",
    "<img align=\"center\" width=\"80%\" src=\"../assets/training.png\">\n",
    "\n",
    "<br/>\n",
    "\n",
    "In the figure above, $F$ is the family of functions that we are considering. These are the second level of assumptions that we make and are what are commonly referred to as **models**.\n",
    "\n",
    "The function $f$ is the output function that we want have learned from the data. \n",
    "\n",
    "For example, a common family of functions $F$ is linear i.e.\n",
    " \n",
    "$$F(x) = m \\cdot x + b$$\n",
    "\n",
    "If we are trying to predict the temperature in Fahrenheit given the temperature in Celsius, then \n",
    "\n",
    "$$f(x) = x \\cdot \\frac{9}{5} + 32$$ \n",
    "\n",
    "where x is the input temperature in Celsius and f(x) is the output temperature in Fahrenheit.\n",
    "\n",
    "The above is just an example and there exist many other families of functions that we can consider. These will be covered in Chapters 10-13. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example\n",
    "\n",
    "The code below uses K-Nearest Neighbors (KNN) to learn the relationship between the features and the target variable.\n",
    "\n",
    "**The `fit` method is used to _train_ the model**. The `fit` method takes two arguments:\n",
    "\n",
    "1. `X_train` - the features of the training data\n",
    "2. `y_train` - the target variable of the training data\n",
    "\n",
    "The `fit` method learns the relationship between the features and the target variable and stores it in the model object.\n",
    "\n",
    "The `fit` method is common to all models in `sklearn` and is used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Phase\n",
    "\n",
    "Once we have learned the function $f$ from the training data, we can apply it to the test data to predict the target variable $\\mathcal{y}$.\n",
    "\n",
    "<img src=\"../assets/testing.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example\n",
    "\n",
    "The code below uses the `predict` method to predict the target variable for the test data.\n",
    "\n",
    "**The `predict` method is used to _test_ the model**. The `predict` method takes one argument:\n",
    "\n",
    "1. `X_test` - the features of the test data\n",
    "\n",
    "The `predict` method applies the learned function $f$ to the test data and returns the predicted target variable.\n",
    "\n",
    "The `predict` method is common to all models in `sklearn` and is used to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = classifier.predict(X_test)\n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "If supervised learning is like school, then the evaluation phase is like the grading phase and criteria. \n",
    "\n",
    "The evaluation phase is where we evaluate how well we have learned the function $f$ from the training data and how well we can predict the target variable $\\mathcal{y}$ from the test data.\n",
    "\n",
    "The exact criteria for evaluation depends on the type of supervised learning problem. That is, evaluation metrics used for classification problems are different from those used for regression problems. These metrics are discussed in detail in the following chapters. \n",
    "\n",
    "<!-- Finally, we evaluate the performance of our model by comparing the predicted values of $\\mathcal{y}$ to the actual values of $\\mathcal{y}$. -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Example\n",
    "\n",
    "The code below uses the `accuracy_score` method to evaluate the performance of the model.\n",
    "\n",
    "**The `accuracy_score` method is used to _evaluate_ the model**. The `accuracy_score` method takes two arguments:\n",
    "\n",
    "1. `y_test` - the actual target variable of the test data\n",
    "2. `y_pred` - the predicted target variable of the test data\n",
    "\n",
    "The `accuracy_score` method compares the predicted target variable to the actual target variable and returns the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Cross Validation\n",
    "\n",
    "Just as most courses in school don't have just the final test, most machine learning problems don't have just one test set either. Often times, it is better to create multiple test sets, evaluate the performance of the model on each of them and then report the average performance of the model. This practice is called **cross validation** in machine learning. \n",
    "\n",
    "<center><img width=\"70%\" src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\"></center>\n",
    "\n",
    "There exist many different ways to create multiple test sets. The most common way is to randomly split the data into multiple randomly sampled train and test sets. This is called **random cross validation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Code Example\n",
    "\n",
    "The code below uses the `cross_val_score` method to perform random cross validation.\n",
    "\n",
    "**The `cross_val_score` method is used to _cross validate_ the model**. The `cross_val_score` method takes four arguments:\n",
    "\n",
    "1. `estimator` - the model object\n",
    "2. `X` - the features of the data\n",
    "3. `y` - the target variable of the data\n",
    "4. `cv` - the number of cross validation splits\n",
    "\n",
    "The `cross_val_score` method performs random cross validation and returns an evaluation metric of the model for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.96666667, 0.9       , 0.9       , 1.        ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(classifier, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
