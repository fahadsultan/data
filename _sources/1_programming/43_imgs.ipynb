{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- An image is a 2D array of pixels. Each pixel is a 3D vector of red, green, and blue (RGB) values. The RGB values are usually represented as integers between 0 and 255. The RGB values are used to represent the color of the pixel. For example, a pixel with RGB values of (255, 0, 0) is red, (0, 255, 0) is green, and (0, 0, 255) is blue. A pixel with RGB values of (0, 0, 0) is black and (255, 255, 255) is white.\n",
    "\n",
    "In this notebook, we will learn how to read and write images, and how to manipulate them. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Read an image\n",
    "img = plt.imread('../data/belltower.jpg');\n",
    "plt.imshow(img); -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- img.shape # (height, width, channels) -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- img[0,0,:] # RGB values of the first pixel -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Convert to grayscale\n",
    "img_gray = img.mean(axis=2)\n",
    "plt.imshow(img_gray, cmap='gray'); -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Invert the image\n",
    "\n",
    "img_inv = 255 - img_gray\n",
    "\n",
    "plt.imshow(img_inv, cmap='gray'); -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Threshold the image\n",
    "\n",
    "img_thresh = img_gray > 100 \n",
    "\n",
    "plt.imshow(img_thresh, cmap='gray'); -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- img.shape -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Crop the image -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- img_crop = img_gray[:700, :700]\n",
    "\n",
    "plt.imshow(img_crop, cmap='gray');\n",
    "\n",
    "# Resize the image\n",
    "\n",
    "img_resize = img_gray[::2, ::2] # every other pixel\n",
    "\n",
    "print(\"Image resized from {} to {}\".format(img_gray.shape, img_resize.shape))\n",
    "\n",
    "plt.imshow(img_resize, cmap='gray');\n",
    "plt.colorbar();\n",
    "\n",
    "# Rotate the image\n",
    "\n",
    "img_rot = img_gray.T\n",
    "\n",
    "plt.imshow(img_rot, cmap='gray');\n",
    "\n",
    "# Flip the image\n",
    "\n",
    "img_flip = img_gray[::-1, ::-1] # reverse the rows and columns\n",
    "\n",
    "plt.imshow(img_flip, cmap='gray');\n",
    "\n",
    "# Save the image\n",
    "\n",
    "plt.imsave('../data/belltower_gray.jpg', img_gray, cmap='gray'); -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "## Exercises\n",
    "\n",
    "**1**. Read in the image `../data/belltower.jpg` and convert it to grayscale. Then, invert the image and save it as `../data/belltower_inv.jpg`.\n",
    "\n",
    "**2**. Read in the image `../data/belltower.jpg` and convert it to grayscale. Then, crop the image to the top-left 700x700 pixels and save it as `../data/belltower_crop.jpg`.\n",
    "\n",
    "**3**. Read in the image `../data/belltower.jpg` and convert it to grayscale. Then, resize the image to half its size and save it as `../data/belltower_resize.jpg`.\n",
    "\n",
    "**4**. Read in the image `../data/belltower.jpg` and convert it to grayscale. Then, rotate the image 90 degrees and save it as `../data/belltower_rot.jpg`.\n",
    "\n",
    "**5**. Read in the image `../data/belltower.jpg` and convert it to grayscale. Then, flip the image vertically and save it as `../data/belltower_flip.jpg`. -->\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Image datasets -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Reading in handwritten digits\n",
    "\n",
    "In this notebook, we will read in the handwritten digits dataset from the UCI Machine Learning Repository. The dataset consists of 1797 images of handwritten digits. Each image is a 2D array of pixels, where each pixel is an integer between 0 and 255. The images are 8x8 pixels, so there are 64 pixels in total. Each image is labeled with the digit it represents.\n",
    "\n",
    "You can find the dataset [here](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits).\n",
    "\n",
    "## Reading in the data\n",
    "\n",
    "The data is stored in a CSV file. We can read it in using `pandas`.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/digits.csv')\n",
    "``` -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
