{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modalities of Data\n",
    "\n",
    "Modality is a term used to describe the way data is represented. For example, a single image is a 2D array of pixels. A video is a sequence of images. A sound is a 1D array of samples. A text is a sequence of characters.\n",
    "\n",
    "There are too many modalities to list them all. Each modality has its own characteristics and requires different methods to process and analyze. Each data modality has its own area of research and expertise. For example, computer vision is the area of research that deals with images and videos. Speech processing is the area of research that deals with sounds. Natural language processing is the area of research that deals with text.\n",
    "\n",
    "In this section, we will discuss the most common modalities of data and how to work with them in Python.\n",
    "\n",
    "The image below shows a 2D array of pixels. Each pixel is a 3D vector of RGB values. The image is 3 pixels wide and 2 pixels high. The first row of pixels is red, green, and blue. The second row of pixels is black, white, and black.\n",
    "\n",
    "There are too many data modalities to enumerate here. \n",
    "\n",
    "We are going to focus on just tabular data. Mathematically, there would be matrix representations.\n",
    "\n",
    "Here are a few covered: \n",
    "\n",
    "1. **Text**: Natural Language Processing, Computational Linguistics\n",
    "2. **Images**: Computer Vision, Digital Image Processing\n",
    "3. **Sounds**: Digital Signal Processing (DSP)\n",
    "4. **Graphs**: Graph Theory, Network Theory\n",
    "5. **Time Series**: Time Series Analysis\n",
    "6. **Geographic**: Geographic Information Systems (GIS), Spatial Computing.\n",
    "\n",
    "Some common modalities are:\n",
    "\n",
    "\n",
    "\n",
    "There are many different ways to represent data. In this section, we will discuss the most common modalities of data and how to work with them in Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words is a method to represent text data when modeling text with machine learning algorithms. It is a way of extracting features from the text for use in machine learning algorithms.\n",
    "\n",
    "### Bag of Words Process\n",
    "\n",
    "1. Collect Data\n",
    "2. Tokenize Data\n",
    "3. Count Tokens\n",
    "4. Create Vocab\n",
    "5. Create Vectors\n",
    "\n",
    "### Bag of Words Example\n",
    "\n",
    "#### Collect Data\n",
    "\n",
    "```python\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!']\n",
    "```\n",
    "\n",
    "#### Tokenize Data\n",
    "\n",
    "```python\n",
    "# split into tokens by white space\n",
    "tokens = [d.split() for d in docs]\n",
    "print(tokens)\n",
    "```\n",
    "\n",
    "    [['Well', 'done!'], ['Good', 'work'], ['Great', 'effort'], ['nice', 'work'], ['Excellent!']]\n",
    "\n",
    "#### Count Tokens\n",
    "    \n",
    "    ```python\n",
    "    # count the tokens\n",
    "    from collections import Counter\n",
    "    counts = Counter()\n",
    "    for d in tokens:\n",
    "        counts.update(d)\n",
    "    print(counts)\n",
    "    ```\n",
    "\n",
    "    Counter({'work': 2, 'Well': 1, 'done!': 1, 'Good': 1, 'Great': 1, 'effort': 1, 'nice': 1, 'Excellent!': 1})\n",
    "\n",
    "#### Create Vocab\n",
    "    \n",
    "    ```python\n",
    "    # create a vocabulary of unique words\n",
    "    vocabulary = set()\n",
    "    for d in tokens:\n",
    "        vocabulary.update(d)\n",
    "    print(vocabulary)\n",
    "    ```\n",
    "\n",
    "    {'effort', 'done!', 'Excellent!', 'Good', 'Great', 'work', 'Well', 'nice'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## TFIDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs are a data structure that consists of a set of nodes (vertices) and a set of edges that relate the nodes to each other. The set of edges describes relationships among the vertices. Graphs are used to model many real-world systems, including computer networks, social networks, and transportation systems.\n",
    "\n",
    "Graphs are a very general structure, so they can be used to model many different kinds of systems. The nodes and edges can have any kind of data associated with them. For example, a graph could be used to represent a social network, where the nodes are people and the edges are friendships. The nodes could have additional data associated with them, such as the person's name, age, and hometown. The edges could have additional data associated with them, such as the date the friendship began."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two common ways to represent a graph as a matrix. The first way is to use an adjacency matrix, which is a matrix where each row and column represents a vertex. If there is an edge from vertex $i$ to vertex $j$, then the entry in row $i$ and column $j$ is 1. Otherwise, the entry is 0. For example, the following matrix represents a graph with 4 vertices and 4 edges:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 & 1 \\\\\n",
    "1 & 0 & 1 & 0 \\\\\n",
    "0 & 1 & 0 & 1 \\\\\n",
    "1 & 0 & 1 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second way to represent a graph as a matrix is to use an edge list. An edge list is a list of pairs of vertices that are connected by an edge. For example, the following edge list represents the same graph as the adjacency matrix above:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 1 \\\\\n",
    "0 & 3 \\\\\n",
    "1 & 2 \\\\\n",
    "2 & 3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjacency Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `networkx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "networkx is a Python library for working with graphs. It provides functions for creating graphs, adding nodes and edges to graphs, and traversing graphs. It also provides functions for computing various properties of graphs, such as the shortest path between two nodes.\n",
    "\n",
    "### Creating Graphs\n",
    "\n",
    "To create a graph, use the `Graph()` function. This function returns a graph object that can be used to add nodes and edges to the graph.\n",
    "\n",
    "### Adding Nodes and Edges\n",
    "\n",
    "To add a node to a graph, use the `add_node()` function. This function takes a single argument, which is the name of the node. To add an edge to a graph, use the `add_edge()` function. This function takes two arguments, which are the names of the nodes that are connected by the edge.\n",
    "\n",
    "### Traversing Graphs\n",
    "\n",
    "To traverse a graph, use the `nodes()` function. This function returns a list of all the nodes in the graph. To traverse a graph, use the `edges()` function. This function returns a list of all the edges in the graph.\n",
    "\n",
    "### Computing Properties of Graphs\n",
    "\n",
    "To compute the shortest path between two nodes in a graph, use the `shortest_path()` function. This function takes two arguments, which are the names of the nodes. It returns a list of the nodes that are on the shortest path between the two nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image is a 2D array of pixels. Each pixel is a 3D vector of red, green, and blue (RGB) values. The RGB values are usually represented as integers between 0 and 255. The RGB values are used to represent the color of the pixel. For example, a pixel with RGB values of (255, 0, 0) is red, (0, 255, 0) is green, and (0, 0, 255) is blue. A pixel with RGB values of (0, 0, 0) is black and (255, 255, 255) is white.\n",
    "\n",
    "In this notebook, we will learn how to read and write images, and how to manipulate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Read an image\n",
    "img = plt.imread('../data/belltower.jpg');\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img.shape # (height, width, channels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img[0,0,:] # RGB values of the first pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to grayscale\n",
    "\n",
    "img_gray = img.mean(axis=2)\n",
    "plt.imshow(img_gray, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Invert the image\n",
    "\n",
    "img_inv = 255 - img_gray\n",
    "\n",
    "plt.imshow(img_inv, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Threshold the image\n",
    "\n",
    "img_thresh = img_gray > 100 \n",
    "\n",
    "plt.imshow(img_thresh, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crop the image\n",
    "img_crop = img_gray[:700, :700]\n",
    "\n",
    "plt.imshow(img_crop, cmap='gray');\n",
    "\n",
    "# Resize the image\n",
    "\n",
    "img_resize = img_gray[::2, ::2] # every other pixel\n",
    "\n",
    "print(\"Image resized from {} to {}\".format(img_gray.shape, img_resize.shape))\n",
    "\n",
    "plt.imshow(img_resize, cmap='gray');\n",
    "plt.colorbar();\n",
    "\n",
    "# Rotate the image\n",
    "\n",
    "img_rot = img_gray.T\n",
    "\n",
    "plt.imshow(img_rot, cmap='gray');\n",
    "\n",
    "# Flip the image\n",
    "\n",
    "img_flip = img_gray[::-1, ::-1] # reverse the rows and columns\n",
    "\n",
    "plt.imshow(img_flip, cmap='gray');\n",
    "\n",
    "# Save the image\n",
    "\n",
    "plt.imsave('../data/belltower_gray.jpg', img_gray, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercises\n",
    "\n",
    "**1**. Read in the image `../data/belltower.jpg` and convert it to grayscale. Then, invert the image and save it as `../data/belltower_inv.jpg`.\n",
    "\n",
    "**2**. Read in the image `../data/belltower.jpg` and convert it to grayscale. Then, crop the image to the top-left 700x700 pixels and save it as `../data/belltower_crop.jpg`.\n",
    "\n",
    "**3**. Read in the image `../data/belltower.jpg` and convert it to grayscale. Then, resize the image to half its size and save it as `../data/belltower_resize.jpg`.\n",
    "\n",
    "**4**. Read in the image `../data/belltower.jpg` and convert it to grayscale. Then, rotate the image 90 degrees and save it as `../data/belltower_rot.jpg`.\n",
    "\n",
    "**5**. Read in the image `../data/belltower.jpg` and convert it to grayscale. Then, flip the image vertically and save it as `../data/belltower_flip.jpg`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in handwritten digits\n",
    "\n",
    "In this notebook, we will read in the handwritten digits dataset from the UCI Machine Learning Repository. The dataset consists of 1797 images of handwritten digits. Each image is a 2D array of pixels, where each pixel is an integer between 0 and 255. The images are 8x8 pixels, so there are 64 pixels in total. Each image is labeled with the digit it represents.\n",
    "\n",
    "You can find the dataset [here](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits).\n",
    "\n",
    "## Reading in the data\n",
    "\n",
    "The data is stored in a CSV file. We can read it in using `pandas`.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/digits.csv')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will learn how to use representations of audio data in machine learning.\n",
    "\n",
    "## Audio data\n",
    "\n",
    "Audio files can be represented in a variety of ways. The most common is the waveform, which is a time series of the amplitude of the sound wave at each time point. The waveform is a one-dimensional array of numbers. The sampling rate is the number of samples per second.\n",
    "\n",
    "| Sampling rate | Quality |\n",
    "|---------------|---------|\n",
    "| 8 kHz         | Telephone call |\n",
    "| 44.1 kHz      | Music CD |\n",
    "| 48 kHz        | DVD |\n",
    "| 96 kHz        | Studio quality |\n",
    "\n",
    "To load an audio file, we can use the `librosa` library. The `librosa.load` function returns the waveform and the sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "waveform, sampling_rate = librosa.load('audio.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset of audio files is available at https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/data.\n",
    "\n",
    "## Spectrogram\n",
    "\n",
    "The spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. It is a two-dimensional array of numbers. The x-axis represents time, the y-axis represents frequency, and the color represents the amplitude of the frequency at that time.\n",
    "\n",
    "The spectrogram can be computed using the `librosa.stft` function. The `librosa.amplitude_to_db` function converts the amplitude to decibels.\n",
    "\n",
    "## Mel spectrogram\n",
    "\n",
    "The mel spectrogram is a spectrogram where the frequencies are converted to the mel scale. The mel scale is a scale of pitches judged by listeners to be equal in distance from one another. The mel spectrogram is a two-dimensional array of numbers. The x-axis represents time, the y-axis represents mel frequency, and the color represents the amplitude of the frequency at that time.\n",
    "\n",
    "The mel spectrogram can be computed using the `librosa.feature.melspectrogram` function.\n",
    "\n",
    "## MFCC\n",
    "\n",
    "The mel-frequency cepstrum (MFC) is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. The MFCC is a one-dimensional array of numbers.\n",
    "\n",
    "The MFCC can be computed using the `librosa.feature.mfcc` function.\n",
    "\n",
    "## Chromagram\n",
    "\n",
    "The chromagram is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. The chromagram is a two-dimensional array of numbers. The x-axis represents time, the y-axis represents pitch class, and the color represents the amplitude of the pitch class at that time.\n",
    "\n",
    "The chromagram can be computed using the `librosa.feature.chroma_stft` function.\n",
    "\n",
    "## Chroma vector\n",
    "\n",
    "The chroma vector is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. The chroma vector is a one-dimensional array of numbers.\n",
    "\n",
    "The chroma vector can be computed using the `librosa.feature.chroma_stft` function.\n",
    "\n",
    "## Chroma deviation\n",
    "\n",
    "The chroma deviation is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. The chroma deviation is a one-dimensional array of numbers.\n",
    "\n",
    "The chroma deviation can be computed using the `librosa.feature.chroma_stft` function.\n",
    "\n",
    "## Chroma distance\n",
    "\n",
    "The chroma distance is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. The chroma distance is a one-dimensional array of numbers.\n",
    "\n",
    "The chroma distance can be computed using the `librosa.feature.chroma_stft` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import librosa\n",
    "\n",
    "waveform, sampling_rate = librosa.load('data/train/audio/bed/00176480_nohash_0.wav')\n",
    "\n",
    "waveform\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
