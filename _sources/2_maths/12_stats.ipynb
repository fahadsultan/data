{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Statistics\n",
    "\n",
    "<!--## Maximum Likelihood Estimation\n",
    "\n",
    "Maximum likelihood estimation (MLE) is a method of estimating the parameters of a probability distribution by maximizing a likelihood function, so that under the assumed statistical model the observed data is most probable. The point in the parameter space that maximizes the likelihood function is called the maximum likelihood estimate.\n",
    "\n",
    "Likelihood function is the probability of observing the data given the parameters.\n",
    "\n",
    "For instance, if we were interested in probability of observing a head in a coin toss, we would use the Bernoulli distribution. The Bernoulli distribution has a single parameter, the probability of success, which we will call $p$. The probability of observing a head is $p$ and the probability of observing a tail is $1-p$. The likelihood function for a single coin toss is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(p) &= p^x(1-p)^{1-x} \\\\\n",
    "&= \\begin{cases}\n",
    "p & \\text{if } x = 1 \\\\\n",
    "1-p & \\text{if } x = 0\n",
    "\\end{cases}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $x$ is the outcome of the coin toss. If we observe a head, then $x=1$ and the likelihood function is $L(p) = p$. If we observe a tail, then $x=0$ and the likelihood function is $L(p) = 1-p$.\n",
    "\n",
    "The \n",
    "\n",
    "## Central Dogma of Statistics\n",
    "\n",
    "The central dogma of statistics is that all data are random samples from some population. The population is the set of all possible observations that could be made. A sample is a subset of observations drawn from the population.\n",
    "\n",
    "<img src=\"file:///Users/fsultan/Downloads/datascience_ml/_build/html/_images/dogma.png\">\n",
    "\n",
    "The central dogma of data science, simply put, is that general claims about a population can be made from a sample of data. This raises all sorts of questions and concerns about the sampling process such as the representativeness of the sample, the size of the sample, the sampling bias, etc. Which in turn raises concerns about potential negative effects of the claims made based on questionable data.\n",
    "\n",
    "\n",
    "## Law of Large Numbers\n",
    "\n",
    "The law of large numbers states that as the number of trials of a random experiment increases, the average of the observed outcomes approaches the expected value. -->\n",
    "\n",
    "<hr/>\n",
    "\n",
    "\n",
    "<!-- Distributions often take on one of the following shapes:\n",
    "\n",
    "- Bell\n",
    "- Long tail\n",
    "- Skewed\n",
    "- Twin peaked\n",
    "- Flat\n",
    "\n",
    "``` {image} https://leanscape.io/wp-content/uploads/2022/10/Different-Type-of-Data-Distributions-1024x577.jpg\n",
    ":alt: Different Type of Data Distributions\n",
    ":width: 100%\n",
    ":align: center\n",
    "```\n",
    "\n",
    "The different shapes can help you to select the best plots and also suggest that some transforms of your data may be useful prior to modeling. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Mean\n",
    "\n",
    "## Geometric Mean\n",
    "\n",
    "## Median\n",
    "\n",
    "## Mode\n",
    "\n",
    "## Maximum Likelihood Estimation\n",
    "\n",
    "## Central Dogma of Statistics -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Hello World')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
