{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random variables are variables that take on random values. They are used to model uncertainty in a system. For example, if we are trying to predict the weather tomorrow, we might use a random variable to represent the temperature. We know that the temperature will be some value, but we don't know what it will be. We can use a random variable to represent this uncertainty.\n",
    "\n",
    "Random variables are usually denoted by capital letters, such as $X$ or $Y$. The values that a random variable can take on are denoted by lower case letters, such as $x$ or $y$.\n",
    "\n",
    "Random variables can be discrete or continuous. Discrete random variables can only take on a finite number of values. For example, if we are rolling a die, we can use a random variable to represent the number that we roll. The random variable can only take on the values 1, 2, 3, 4, 5, or 6. Continuous random variables can take on any value in a range. For example, if we are measuring the temperature, we can use a random variable to represent the temperature. The random variable can take on any value between -273.15 and infinity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Space $\\Omega$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample space is the set of all possible outcomes of an experiment. For example, if we are rolling a die, the sample space is the set of all possible numbers that we can roll. The sample space is usually denoted by $\\Omega$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coin Flip 1 | Coin Flip 2 |\n",
    "------------| ------------|\n",
    "H | H |\n",
    "H | T |\n",
    "T | H |\n",
    "T | T |\n",
    "\n",
    "Sample Space $\\Omega$ (uppercase omega) is the set of all possible worlds \n",
    "\n",
    "$\\Omega = \\{HH, HT, TH, TT\\}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible World $\\omega_i$\n",
    "\n",
    "A possible world is a possible outcome of an experiment. For example, if we are rolling a die, a possible world is the number that we roll. A possible world is usually denoted by $\\omega_i$.\n",
    "\n",
    "Possible world | Coin Flip 1 | Coin Flip 2 |\n",
    "---------------|------------| ------------|\n",
    "$\\omega_1$ | H | H |\n",
    "$\\omega_2$ | H | T |\n",
    "$\\omega_3$ | T | H |\n",
    "$\\omega_4$ | T | T |\n",
    "\n",
    "Sample space $\\Omega$ is"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Model $P(\\omega)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability model is a function that assigns a probability to each possible world. For example, if we are rolling a die, the probability model assigns a probability to each number that we can roll. The probability model is usually denoted by $P(\\omega)$.\n",
    "\n",
    "Possible world | Coin Flip 1 | Coin Flip 2 | $P(\\omega)$ |\n",
    "---------------|------------| ------------|-------------|\n",
    "$\\omega_1$ | H | H | 0.25 |\n",
    "$\\omega_2$ | H | T | 0.25 |\n",
    "$\\omega_3$ | T | H | 0.25 |\n",
    "$\\omega_4$ | T | T | 0.25 |\n",
    "\n",
    "Sample space $\\Omega$ is the set of all possible worlds "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ 0 \\lt P(\\omega_i) \\lt 1 \\text{~for every~} \\omega_i$$ \n",
    "\n",
    "$$ \\sum_{\\omega \\in \\Omega} P(\\omega_i) = 1$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random variables can be either independent or dependent. If two random variables are independent, then the value of one random variable does not affect the value of the other random variable. For example, if we are rolling two dice, we can use two random variables to represent the numbers that we roll. The two random variables are independent because the value of one die does not affect the value of the other die. If two random variables are dependent, then the value of one random variable does affect the value of the other random variable. For example, if we are measuring the temperature and the humidity, we can use two random variables to represent the temperature and the humidity. The two random variables are dependent because the temperature affects the humidity and the humidity affects the temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Probability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint probability is the probability of two events occurring together. For example, if we are rolling two dice, the joint probability is the probability of rolling a 1 on the first die and a 2 on the second die. The joint probability is usually denoted by $P(A, B)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(A, B) = P(A | B) \\cdot P(B) = P(B | A) \\cdot P(A)$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Data Science, we rarely know the true joint probability. Instead, we estimate the joint probability from data. For example, if we are rolling two dice, we can estimate the joint probability by counting the number of times that we roll a 1 on the first die and a 2 on the second die and dividing by the total number of rolls."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probability\n",
    "\n",
    "Conditional probability is the probability of one event occurring given that another event has occurred. \n",
    "\n",
    "For example, if we are rolling two dice, the conditional probability is the probability of rolling a 1 on the first die given that we rolled a 2 on the second die. The conditional probability is usually denoted by $P(A | B)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(A | B) = \\frac{P(A, B)}{P(B)} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginalizing from Joint Probability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal probability is the probability of one event occurring. For example, if we are rolling two dice, the marginal probability is the probability of rolling a 1 on the first die. The marginal probability is usually denoted by $P(A)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(A) = \\sum_{B=b} P(A, B) $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Theorem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes theorem is a way of calculating conditional probability. For example, if we are rolling two dice, Bayes theorem can be used to calculate the probability of rolling a 1 on the first die given that we rolled a 2 on the second die.\n",
    "\n",
    "$$ P(A | B) = \\frac{P(B | A) \\cdot P(A)}{P(B)} $$\n",
    "\n",
    "$P(A|B)$ in the context of Bayes theorem is called the posterior probability. \n",
    "\n",
    "$P(B|A)$ is called the likelihood. \n",
    "\n",
    "$P(A)$ is called the prior probability. \n",
    "\n",
    "$P(B)$ is called the marginal likelihood."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(\\text{Posterior}) = \\frac{P(\\text{Likelihood})\\cdot P(\\text{Prior})}{P(\\text{Evidence})}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Expectation\n",
    "\n",
    "Expectation is the average value of a random variable. For example, if we are rolling a die, the expectation is the average value of the number that we roll. The expectation is usually denoted by $E(X)$.\n",
    "\n",
    "$$ E(X) = \\sum_{x \\in X} x \\cdot P(X=x) $$\n",
    "\n",
    "## Variance\n",
    "\n",
    "Variance is a measure of how spread out a random variable is. For example, if we are rolling a die, the variance is a measure of how spread out the numbers that we roll are. The variance is usually denoted by $Var(X)$.\n",
    "\n",
    "$$ Var(X) = E((X - E(X))^2) = E(X^2) - E(X)^2 $$\n",
    "\n",
    "## Covariance\n",
    "\n",
    "Covariance is a measure of how two random variables vary together. For example, if we are rolling two dice, the covariance is a measure of how the numbers that we roll on the two dice vary together. The covariance is usually denoted by $Cov(X, Y)$.\n",
    "\n",
    "$$ Cov(X, Y) = E((X - E(X)) \\cdot (Y - E(Y))) = E(X \\cdot Y) - E(X) \\cdot E(Y) $$\n",
    "\n",
    "## Correlation\n",
    "\n",
    "Correlation is a measure of how two random variables vary together. For example, if we are rolling two dice, the correlation is a measure of how the numbers that we roll on the two dice vary together. The correlation is usually denoted by $Corr(X, Y)$.\n",
    "\n",
    "$$ Corr(X, Y) = \\frac{Cov(X, Y)}{\\sqrt{Var(X) \\cdot Var(Y)}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
