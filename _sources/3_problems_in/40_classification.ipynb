{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "\n",
    "Most machine learning problems involve predicting a single random variable $\\mathcal{y}$ from one or more random variables $\\mathcal{X}$. \n",
    "\n",
    "The underlying assumption, when we set out to accomplish this, is that the value of $\\mathcal{y}$ is dependent on the value of $\\mathcal{X}$ and the relationship between the two is governed by some unknown function $f$ i.e. \n",
    "\n",
    "$$ \\mathcal{y = f(X)} $$\n",
    "\n",
    "$\\mathcal{X}$ is here simply some data that we have as a pandas Dataframe `pd.DataFrame` whereas $\\mathcal{y}$ here is the target variable, one value for each observation, that we want to predict, as a pandas Series `pd.Series`.\n",
    "\n",
    "<img width=\"80%\" align=\"center\" src=\"../assets/supervised2.png\">\n",
    "\n",
    "<br/>\n",
    "\n",
    "The figure above just depicts the core assumption underlying most machine learning problems. \n",
    "\n",
    "**Assumptions**, loosely speaking, are what we formally call **models**. \n",
    "\n",
    "Therefore, the basic mathematical model underlying most machine learning problems is that the target variable $\\mathcal{y}$ is a function of the input variables $\\mathcal{X}$ i.e. $\\mathcal{y = f(X)}$.\n",
    "\n",
    "<hr/>\n",
    "\n",
    "The **core problem**, distinct from any models or assumptions, here is that <u>the function $\\mathcal{f}$ is unknown to us and we need to <i>\"learn\"</i> it from the data</u>. \n",
    "\n",
    "\n",
    "Such problems fall under the broad category of **Supervised Learning**. In such problems, we have a set of observations, each observation consisting of a set of input variables $\\mathcal{X}$ and a target variable $\\mathcal{y}$, and we want to learn a function $\\mathcal{f}$ that maps the input $\\mathcal{X}$ to the output $\\mathcal{y}$.\n",
    "\n",
    "\n",
    "<img align=\"center\" width=\"80%\" src=\"../assets/supervised1.png\">\n",
    "\n",
    "**Classification** is the case where **$\\mathcal{y}$ is a <a src=\"../1_programming/41_types.html#categorical-features\">discrete categorical variable</a>**. For example, we might want to predict whether a patient has a disease or not, based on their symptoms. In this case, $\\mathcal{y}$ is a binary variable, taking the value 1 if the patient has the disease, and 0 otherwise. Other examples of classification problems include predicting the sentiment of a movie review: positive, negative, or neutral.\n",
    "\n",
    "The classification problem is to learn a function $f$ that maps the input $\\mathcal{X}$ to the discrete output $\\mathcal{Y}$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Classification lies at the heart of both human and machine intelligence. Deciding what letter, word, or image has been presented to our senses, recognizing faces or voices, sorting mail, assigning grades to homeworks; these are all examples of assigning a category to an input.\n",
    "\n",
    "The goal of classification is to take a single observation, extract some useful\n",
    "features, and thereby classify the observation into one of a set of discrete classes.\n",
    "One method for classifying text is to use handwritten rules. There are many areas of\n",
    "language processing where handwritten rule-based classifiers constitute a state-ofthe-art system, or at least part of it.\n",
    "\n",
    "We focus on one common text categorization task, sentiment analysis, the ex- sentiment\n",
    "analysis\n",
    "traction of sentiment, the positive or negative orientation that a writer expresses\n",
    "toward some object. A review of a movie, book, or product on the web expresses the\n",
    "author’s sentiment toward the product, while an editorial or political text expresses\n",
    "sentiment toward a candidate or political action. Extracting consumer or public sentiment is thus relevant for fields from marketing to politics.\n",
    "\n",
    "Spam detection is another important commercial application, the binary classification task of assigning an email to one of the two classes spam or not-spam.\n",
    "Many lexical and other features can be used to perform this classification. For example you might quite reasonably be suspicious of an email containing phrases like\n",
    "“online pharmaceutical” or “WITHOUT ANY COST” or “Dear Winner”.\n",
    "\n",
    "Rules can be fragile, however, as situations or data change over time, and for\n",
    "some tasks humans aren’t necessarily good at coming up with the rules. Most cases\n",
    "of classification in language processing are instead done via supervised machine\n",
    "learning, and this will be the subject of the remainder of this chapter. In supervised\n",
    "supervised\n",
    "machine\n",
    "learning learning, we have a data set of input observations, each associated with some correct\n",
    "output (a ‘supervision signal’). The goal of the algorithm is to learn how to map\n",
    "from a new observation to a correct output.\n",
    "Formally, the task of supervised classification is to take an input x and a fixed\n",
    "set of output classes Y = {y1, y2,..., yM} and return a predicted class y ∈ Y. For\n",
    "text classification, we’ll sometimes talk about c (for “class”) instead of y as our\n",
    "output variable, and d (for “document”) instead of x as our input variable. In the\n",
    "supervised situation we have a training set of N documents that have each been handlabeled with a class: {(d1, c1),....,(dN, cN)}. Our goal is to learn a classifier that is\n",
    "capable of mapping from a new document d to its correct class c ∈ C, where C is\n",
    "some set of useful document classes. A probabilistic classifier additionally will tell\n",
    "us the probability of the observation being in the class. This full distribution over\n",
    "the classes can be useful information for downstream decisions; avoiding making\n",
    "discrete decisions early on can be useful when combining system\n",
    "\n",
    "Many kinds of machine learning algorithms are used to build classifiers. This\n",
    "chapter introduces naive Bayes; the following one introduces logistic regression.\n",
    "These exemplify two ways of doing classification. Generative classifiers like naive\n",
    "Bayes build a model of how a class could generate some input data. Given an observation, they return the class most likely to have generated the observation. Discriminative classifiers like logistic regression instead learn what features from the\n",
    "input are most useful to discriminate between the different possible classes. While\n",
    "discriminative systems are often more accurate and hence more commonly used,\n",
    "generative classifiers still have a role\n",
    "\n",
    "<img src=\"../assets/classification.png\">\n",
    "\n",
    "\n",
    "<img src=\"../assets/cross_validation.png\">\n",
    "\n",
    "\n",
    "<img src=\"../assets/training_testing.png\">\n",
    "\n",
    "\n",
    "<img src=\"../assets/sentiment.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
